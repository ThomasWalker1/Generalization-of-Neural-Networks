# Generalization-of-Neural-Networks

This repository contains the code for an undergraduate research project I conducted in the summer of 2023. The project looks into the current state of theory regarding the generalization of deep neural networks. Throughout the repository, the generalization bounds proposed by various papers are tested and investigated. Furthermore, some of the work is my own work that extends the concepts in the papers and links them together in a concise and coherent manner. The aim of the project is to understand how current literature intertwines to give us an understanding of how deep neural networks generalize.

| Title of Paper      | Paper PDF | Section of Project Report | Project Code
| ----------- | ----------- | ----------- | ----------- |
| Generalization In Deep Learning|[PDF](https://arxiv.org/pdf/1710.05468.pdf)| | [CODE](https://github.com/ThomasWalker1/Generalization-of-Neural-Networks/tree/main/Generalization%20in%20Deep%20Learning) |
| Computing Nonvacuous Generalization Bonds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data|[PDF]([https://arxiv.org/pdf/1710.05468.pdf](https://arxiv.org/pdf/1703.11008.pdf))| | [CODE]() |
| Generalization In Deep Learning|[PDF]()| | [CODE]() |
| Generalization In Deep Learning|[PDF]()| | [CODE]() |
| Generalization In Deep Learning|[PDF]()| | [CODE]() |
