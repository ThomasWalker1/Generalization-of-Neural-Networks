(Habib, 1998) Michel Habib, Colin McDiarmid, Jorge Ramirez-Alfonsin, Bruce Reed. Probabilistic Methods for Algorithmic Discrete Mathematics. 1998\
(McAllester, 1999) D. A. McAllester. PAC-Bayesian model averaging. In Proceedings of the twelfth annual conference on Computational learning theory, pages 164–170, 1999.\
(Seeger, 2001) John Langford and Matthias Seeger. “Bounds for Averaging Classifiers”. In: (Feb. 2001).\
(Maurer, 2004) Andreas Maurer. “A Note on the PAC Bayesian Theorem”. In: CoRR (2004).\
(Mitzenmacher, 2005) Michael Mitzenmacher and Eli Upfal. Probability and Computing: Randomized Algorithms and Probabilistic Analysis. Cambridge University Press, 2005.\
(Blanchard, 2007) Gilles Blanchard and François Fleuret. Occam’s Hammer. In COLT, pages 112–126, 2007.\
(Catoni, 2007) Olivier Catoni. “Pac-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning”. In: IMS Lecture Notes Monograph Series 56 (2007), pp. 1–163.\
(Catoni, 2009) Olivier Catoni. “A PAC-Bayesian approach to adaptive classification”. In: (Jan. 2009).\
(Balcan, 2011) Maria-Florina Balcan. Rademacher Complexity. 2011.\
(McAllester, 2013) David A. McAllester. “A PAC-Bayesian Tutorial with A Dropout Bound”. In: CoRR (2013).\
(Scott(a), 2014) Clayton Scott. Hoeffding’s Inequality. 2014.\
(Scott(b), 2014) Clayton Scott. Rademacher Complexity. 2014.\
(Scott(c), 2014) Clayton Scott. The Bounded Difference Inequality. 2014.\
(Choi, 2017) Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Towards the Limit of Network Quantization. 2017.\
(Dziugaite, 2017) Gintare Karolina Dziugaite and Daniel M. Roy. “Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data”. In: CoRR (2017).\
(Neyshabur, 2017) Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro. “A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks”. In: CoRR (2017).\
(Arora, 2018) S. Arora, R. Ge, B. Neyshabur, and Y. Zhang. “Stronger generalization bounds for deep nets via a compression approach”. In: CoRR (2018).\
(Guedj, 2019) Benjamin Guedj. A Primer on PAC-Bayesian Learning. 2019.\
(Zhou, 2019) Wenda Zhou, Victor Veitch, Morgane Austern, Ryan P. Adams, and Peter Orbanz. Non-Vacuous Generalization Bounds at the ImageNet Scale: A PAC-Bayesian Compression Approach. 2019.\
(Dziugaite, 2020) Gintare Karolina Dziugaite, Kyle Hsu,Waseem Gharbieh, and Daniel M. Roy. “On the role of data in PAC-Bayes bounds”. In: CoRR (2020).\
(Lotz, 2020) Martin Lotz. Covering Numbers. 2020.\
(Rivasplata, 2020) Omar Rivasplata, Ilja Kuzborskij, Csaba Szepesvári, and John Shawe-Taylor. PAC-Bayes Analysis Beyond the Usual Bounds. In NeurIPS, 2020.\
(Rodriguez, 2021) Pierre-Francois Rodriguez. Lebesgue Measure and Integration. 2021.\
(Viallard, 2021) Paul Viallard, Pascal Germain, Amaury Habrard, and Emilie Morvant. A General Framework for the Disintegration of PAC-Bayesian Bounds. 2021.\
(Lotfi, 2022) Sanae Lotfi, Marc Finzi, Sanyam Kapoor, Andres Potapczynski, Micah Goldblum, and Andrew Gordon Wilson. PAC-Bayes Compression Bounds So Tight That They Can Explain Generalization. 2022.\
(Rebeschini, 2022) Patrick Rebeschini. Algorithmic Foundations of Learning. Nov. 2022.\
(Alquier, 2023) Pierre Alquier. User-friendly introduction to PAC-Bayes bounds. 2023.